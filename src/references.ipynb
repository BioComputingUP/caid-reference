{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6883c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:27:53.417537Z",
     "start_time": "2024-10-29T09:27:53.119837Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx\n",
    "import numpy as np\n",
    "import obonet  # conda install -c biobuilds obonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d9a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:27:54.164045Z",
     "start_time": "2024-10-29T09:27:54.160976Z"
    }
   },
   "outputs": [],
   "source": [
    "go_obo_file = \"../data/disprot/go-basic.obo\"\n",
    "\n",
    "# Mongo collections\n",
    "disprot_old_file = \"../data/disprot/disprot8.entries_2023_12.json\"\n",
    "#disprot_new_file = \"../data/disprot/disprot8.entries_2024_06_c.json\"\n",
    "disprot_new_file = \"../data/disprot/disprot8.entries_2024_12_c.json\"  # 29 October 2024 (10:15 CET)\n",
    "\n",
    "# Download from SIFTS\n",
    "sifts_file = \"../data/sifts/uniprot_segments_observed.tsv.gz\"\n",
    "accession_filter_file = None #\"../data/accession_filter.txt\"  # Limit the reference to these accessions\n",
    "\n",
    "# Output\n",
    "references_dir = \"../data/output/references\"\n",
    "dataset_raw_file = \"../data/output/dataset_raw.tsv\"\n",
    "dataset_ec_file = \"../data/output/dataset_ec.tsv\"\n",
    "challenge_terms_file = \"../data/output/challenge_terms.tsv\"\n",
    "dataset_file = \"../data/output/dataset.tsv\"\n",
    "fasta_new_file = \"../data/output/homology/disprot_new.fasta\"\n",
    "fasta_old_file = \"../data/output/homology/disprot_old.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f713e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:27:55.272487Z",
     "start_time": "2024-10-29T09:27:55.268609Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_region(df_:pd.DataFrame, start_col:str='start', end_col:str='end', res_col:str='reg_position') -> pd.DataFrame:\n",
    "    df_[res_col] = list(range(int(df_[start_col]), int(df_[end_col]) + 1, 1))\n",
    "    return df_\n",
    "\n",
    "def expand_sequence(df_:pd.DataFrame, seq_column:str='sequence', res_col:str='seq_aa') -> pd.DataFrame:\n",
    "    df_[res_col] = [(i+1, aa) for i, aa in enumerate(df_[seq_column])]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a9e33",
   "metadata": {},
   "source": [
    "## Associate DisProt annotation terms to CAID challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755b664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:28:01.188241Z",
     "start_time": "2024-10-29T09:28:01.184714Z"
    }
   },
   "outputs": [],
   "source": [
    "# IDPO terms\n",
    "data_idpo = [\n",
    "            ('IDPO:00076', 'disorder', 'disorder'), ('IDPO:00077', 'disorder', 'molten-globule'), ('IDPO:00078', 'disorder', 'pre-molten-globule'), \n",
    "    \n",
    "            ('IDPO:00502', 'linker', 'flexible linker/spacer'),\n",
    "    \n",
    "            ('IDPO:00049', 'transition'), \n",
    "            ('IDPO:00050', 'transition'), ('IDPO:00051', 'transition'), ('IDPO:00052', 'transition'), ('IDPO:00053', 'transition'), ('IDPO:00060', 'transition'), ('IDPO:00055', 'transition'), \n",
    "            ('IDPO:00056', 'transition'), ('IDPO:00061', 'transition'), ('IDPO:00054', 'transition'), ('IDPO:00057', 'transition'), ('IDPO:00058', 'transition'), ('IDPO:00059', 'transition')]\n",
    "\n",
    "# ('IDPO:00501', 'linker', 'entropic chain'),  ('IDPO:00503', 'linker', 'flexible C-terminal tail'), ('IDPO:00504', 'linker', 'flexible N-terminal tail')\n",
    "\n",
    "# GO ancestor terms corresponding to CAID2 challenges\n",
    "ancestors = {'GO:0005488': 'binding', 'GO:0003676': 'binding nucleic acid', 'GO:0005515': 'binding protein'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab573d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:28:09.055765Z",
     "start_time": "2024-10-29T09:28:04.948404Z"
    }
   },
   "outputs": [],
   "source": [
    "# The OBO must have \"ontology: GO\" header (first line)\n",
    "graph = obonet.read_obo(go_obo_file)\n",
    "\n",
    "# Remove all edges which are not \"is_a\"\n",
    "to_remove = []\n",
    "for e in graph.edges:\n",
    "    if e[2] != 'is_a':\n",
    "        to_remove.append((e[0], e[1]))\n",
    "for ele in to_remove:\n",
    "    graph.remove_edge(*ele)\n",
    "    \n",
    "# Create children table\n",
    "data_go = []    \n",
    "for node in graph.nodes(data=True):\n",
    "    challenge = ancestors.get(node[0])\n",
    "    if challenge is not None:\n",
    "        data_go.append([node[0], challenge])\n",
    "        for children in networkx.ancestors(graph, node[0]): \n",
    "            data_go.append([children, challenge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a327bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:28:12.949443Z",
     "start_time": "2024-10-29T09:28:12.932995Z"
    }
   },
   "outputs": [],
   "source": [
    "df_challenge = pd.DataFrame(data=data_idpo + data_go, columns=['term_id', 'challenge', 'term_name']).drop_duplicates()\n",
    "df_challenge.to_csv(challenge_terms_file, sep=\"\\t\", index=False)\n",
    "df_challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1453d",
   "metadata": {},
   "source": [
    "## Process DisProt annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227c32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T09:31:03.219931Z",
     "start_time": "2024-05-21T09:31:03.208043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get DisProt annotations (mjson format)\n",
    "# disprot_old = {}\n",
    "# with open(disprot_old_file, \"r\") as f:\n",
    "#     for line in f:\n",
    "#         obj = json.loads(line)\n",
    "#         disprot_old[obj[\"disprot_id\"]] = obj\n",
    "#         \n",
    "# disprot_new = {}\n",
    "# with open(disprot_new_file, \"r\") as f:\n",
    "#     for line in f:\n",
    "#         obj = json.loads(line)\n",
    "#         disprot_new[obj[\"disprot_id\"]] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457c0ed5437b067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:40:04.561054Z",
     "start_time": "2024-10-29T09:40:03.408184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get DisProt annotations (json format)\n",
    "disprot_old = {}\n",
    "with open(disprot_old_file, \"r\") as f:\n",
    "     for obj in json.load(f):\n",
    "         disprot_old[obj[\"disprot_id\"]] = obj\n",
    "         \n",
    "# disprot_new = {}\n",
    "# with open(disprot_new_file, \"r\") as f:\n",
    "#      for obj in json.load(f):\n",
    "#          disprot_new[obj[\"disprot_id\"]] = obj\n",
    "         \n",
    "# From a mongoexport of the collection\n",
    "disprot_new = {}\n",
    "with open(disprot_new_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        disprot_new[obj[\"disprot_id\"]] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd44ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:40:18.717073Z",
     "start_time": "2024-10-29T09:40:18.710941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get new annotations (delta = new - old)\n",
    "dataset = []  # New valid annotations\n",
    "for disprot_id in disprot_new:\n",
    "    if disprot_id not in disprot_old and \"obsolete\" not in disprot_new[disprot_id]:\n",
    "        if \"X\" not in disprot_new[disprot_id][\"sequence\"]:\n",
    "            # Filter out obsolete regions\n",
    "            disprot_new[disprot_id][\"regions\"] = [region for region in disprot_new[disprot_id][\"regions\"] if \"obsolete\" not in region]\n",
    "            if disprot_new[disprot_id][\"regions\"]:\n",
    "                dataset.append(disprot_new[disprot_id])\n",
    "            else:\n",
    "                print(\"{} excluded, only obsolete regions\".format(disprot_id))\n",
    "        else:\n",
    "            print(\"{} excluded, contains X\".format(disprot_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b8ecc3d661bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:40:45.099295Z",
     "start_time": "2024-10-29T09:40:45.095499Z"
    }
   },
   "outputs": [],
   "source": [
    "# WARNING\n",
    "# Filter accession given an input list\n",
    "if accession_filter_file is not None:\n",
    "    filter_list = set()\n",
    "    with open(accession_filter_file) as f:\n",
    "        for line in f:\n",
    "            filter_list.add(line.strip())\n",
    "    dataset = list(filter(lambda x: x['disprot_id'] in filter_list, dataset))\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1633f85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:40:52.733648Z",
     "start_time": "2024-10-29T09:40:52.724360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write fasta for homology calculation\n",
    "with open(fasta_new_file, \"w\") as fout:\n",
    "    for obj in dataset:\n",
    "        fout.write(\">{}|{}\\n{}\\n\".format(obj['disprot_id'], obj['acc'], obj['sequence']))\n",
    "\n",
    "with open(fasta_old_file, \"w\") as fout:\n",
    "    for disprot_id, obj in disprot_old.items():\n",
    "        if \"obsolete\" not in obj:\n",
    "            fout.write(\">{}|{}\\n{}\\n\".format(obj['disprot_id'], obj['acc'], obj['sequence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2bebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:46:45.541421Z",
     "start_time": "2024-10-29T09:46:45.475005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert json to dataframe\n",
    "entry_columns = ['disprot_id', 'acc', 'ncbi_taxon_id', 'organism', 'sequence']\n",
    "df = pd.json_normalize(data=dataset, record_path=['regions'], meta=entry_columns, meta_prefix='', record_prefix='')\n",
    "df = pd.merge(left=df, right=df_challenge, how=\"inner\", on=\"term_id\")\n",
    "df.to_csv(dataset_raw_file, sep=\"\\t\", index=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0972a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:46:48.254055Z",
     "start_time": "2024-10-29T09:46:48.242892Z"
    }
   },
   "outputs": [],
   "source": [
    "region_columns = [\"start\", \"end\", \"term_id\", \"ec_id\", \"challenge\"]\n",
    "df = df.loc[:, entry_columns + region_columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e37b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:46:51.871558Z",
     "start_time": "2024-10-29T09:46:51.478229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dataset sequences (1 residue per row)\n",
    "df_sequence = df.apply(expand_sequence, axis=1).copy(deep=True).drop(columns=[\"ncbi_taxon_id\", \"organism\", \"start\", \"end\", \"sequence\", \"term_id\", \"ec_id\", 'challenge'])\n",
    "df_sequence = df_sequence.explode(\"seq_aa\")\n",
    "df_sequence[['pos', 'aa']] = pd.DataFrame(df_sequence['seq_aa'].tolist(), index=df_sequence.index)\n",
    "df_sequence = df_sequence.drop(columns='seq_aa').drop_duplicates()\n",
    "df_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19bc31",
   "metadata": {},
   "source": [
    "## Map PDB observed positions using SIFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6abc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:46:56.902835Z",
     "start_time": "2024-10-29T09:46:54.838194Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sifts = pd.read_csv(sifts_file, sep=\"\\t\", header=1)\n",
    "# Filter for dataset entries\n",
    "df_sifts = df_sifts.loc[df_sifts['SP_PRIMARY'].isin(df_sequence['acc'])]\n",
    "# Explode observed regions \n",
    "df_sifts = df_sifts.apply(expand_region, start_col=\"SP_BEG\", end_col=\"SP_END\", axis=1)\n",
    "df_sifts = df_sifts.explode(\"reg_position\")\n",
    "df_sifts = df_sifts.loc[:, ['SP_PRIMARY', 'reg_position']].drop_duplicates().reset_index(drop=True).rename(columns={\"SP_PRIMARY\": \"acc\"})\n",
    "df_sifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a06b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:46:59.837214Z",
     "start_time": "2024-10-29T09:46:59.792530Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sequence = pd.merge(df_sequence, df_sifts, left_on=[\"acc\", \"pos\"], right_on=[\"acc\", \"reg_position\"], how=\"left\")\n",
    "df_sequence.rename(columns={\"reg_position\": \"pdb\"}, inplace=True)\n",
    "df_sequence.loc[df_sequence['pdb'].notnull(), 'pdb'] = 1.0\n",
    "df_sequence.loc[df_sequence['pdb'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95438b0",
   "metadata": {},
   "source": [
    "## Define regions\n",
    "\n",
    "Transform the per-protein dataframe into a per-residue dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe3f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:02.587254Z",
     "start_time": "2024-10-29T09:47:02.393004Z"
    }
   },
   "outputs": [],
   "source": [
    "df_regions = df.apply(expand_region, axis=1).loc[:, [\"disprot_id\", \"reg_position\", \"ec_id\", \"challenge\"]].copy(deep=True)\n",
    "# df_regions = pd.merge(left=df_regions, right=df_challenge, how=\"inner\", left_on=\"term_id\", right_on=\"term_id\").drop(columns=[\"term_id\"])\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca05a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:05.413761Z",
     "start_time": "2024-10-29T09:47:05.403527Z"
    }
   },
   "outputs": [],
   "source": [
    "# ECO:0006220, X-ray crystallography-based structural model with missing residue coordinates used in manual assertion  \n",
    "df_ = df_regions.loc[(df_regions['challenge'] == 'disorder') & (df_regions['ec_id'] != 'ECO:0006220')]\n",
    "df_.loc[:, 'challenge'] = 'disorder_nox'\n",
    "df_regions = pd.concat([df_regions, df_])\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e87534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:08.132904Z",
     "start_time": "2024-10-29T09:47:08.109301Z"
    }
   },
   "outputs": [],
   "source": [
    "df_regions_all = df_regions.drop(columns=['ec_id']).explode(\"reg_position\").drop_duplicates()\n",
    "df_regions_all['has_region'] = 1\n",
    "df_regions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d041721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:10.599865Z",
     "start_time": "2024-10-29T09:47:10.570427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the pivot table. Transpose challenge values into columns \n",
    "df_regions_all = pd.pivot_table(\n",
    "    df_regions_all,\n",
    "    columns=\"challenge\",\n",
    "    index=['disprot_id', 'reg_position'],\n",
    "    values='has_region')\n",
    "df_regions_all = df_regions_all.reset_index()\n",
    "df_regions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01af92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:19.309546Z",
     "start_time": "2024-10-29T09:47:19.261241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add sequence positions not mapping to any DisProt region\n",
    "df_regions_all = pd.merge(left=df_regions_all, right=df_sequence, how=\"right\", left_on=[\"disprot_id\", \"reg_position\"], right_on=[\"disprot_id\", \"pos\"])\n",
    "df_regions_all.drop(columns=\"reg_position\", inplace=True)\n",
    "df_regions_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3db36",
   "metadata": {},
   "source": [
    "## Write files\n",
    "\n",
    "Challenge definitions\n",
    "\n",
    "- The first list are the columns to be considered as positive (any)\n",
    "- The second list (mask) are the columns to be considered as negative (any)\n",
    "- If the second list is not provided all non-positives are considered negatives\n",
    "- In case of conflicts, the positives always overwrite the negatives\n",
    "- If mask is provided proteins without at least one residue that could be masked (even when overwritten by a positive) are excluded (e.g. only proteins with PDB observed residues are considered) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f17c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:22.900453Z",
     "start_time": "2024-10-29T09:47:22.885444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reorder the columns\n",
    "head_cols = ['disprot_id', 'acc', 'pos', 'aa']\n",
    "disprot_cols = list(df_challenge['challenge'].unique())\n",
    "other_cols = sorted(list((set(df_regions_all.columns.tolist()) - set(head_cols)) - set(disprot_cols)))\n",
    "cols = head_cols + disprot_cols + other_cols\n",
    "df_regions_all = df_regions_all[cols]\n",
    "df_regions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c5d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:26.336860Z",
     "start_time": "2024-10-29T09:47:26.127663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the dataframe\n",
    "df_regions_all.to_csv(dataset_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8ffa5",
   "metadata": {},
   "source": [
    "### Write references (Fasta format)\n",
    "\n",
    "* The next element overwrites the previous in the \"class\" list\n",
    "* The \"fill\" field is used to fill unassigned positions\n",
    "* Only proteins with at least a \"1\" are written to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef5c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:47:30.038536Z",
     "start_time": "2024-10-29T09:47:28.387259Z"
    }
   },
   "outputs": [],
   "source": [
    "challenges = {'linker': {'class': [('linker', '1')], 'fill': '0'}, \n",
    "              'linker_disorder': {'class': [('disorder', '0'), ('linker', '1')], 'fill': '-'},\n",
    "              'disorder': {'class': [('disorder', '1')], 'fill': '0'}, \n",
    "              'disorder_nox': {'class': [('disorder_nox', '1')], 'fill': '0'}, \n",
    "              'disorder_pdb': {'class': [('pdb', '0'), ('disorder', '1')], 'fill': '-'},\n",
    "              'disorder_pdb_fill': {'class': [('pdb', '0'), ('disorder', '1')], 'fill': '1'},\n",
    "              'binding': {'class': [('binding', '1')], 'fill': '0'},\n",
    "              'binding_nucleic_acid': {'class': [('binding nucleic acid', '1')], 'fill': '0'},\n",
    "              'binding_disorder': {'class': [('disorder', '0'), ('binding', '1')], 'fill': '-'},\n",
    "             }\n",
    "\n",
    "for file_name, challenge in challenges.items():\n",
    "    with open(\"{}/{}.fasta\".format(references_dir, file_name), \"w\") as fout:\n",
    "        for disprot_id, df_g in df_regions_all.groupby('disprot_id'):\n",
    "            df_g['output'] = np.nan\n",
    "            # Assign class\n",
    "            for column, value in challenge['class']:\n",
    "                df_g.loc[df_g[column].notnull(), 'output'] = value\n",
    "            # Fill\n",
    "            if df_g['output'].notnull().any() and challenge.get('fill'):\n",
    "                df_g.loc[df_g['output'].isnull(), 'output'] = challenge['fill'] \n",
    "            # Write proteins with at least one positive assignment\n",
    "            if (df_g['output'] == '1').any():\n",
    "                fout.write(\">{}\\n{}\\n{}\\n\".format(disprot_id, \"\".join(df_g['aa']), \"\".join(df_g['output'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
